--- 
knit: "bookdown::preview_chapter"
---

# Cause and Effect {#causeeffect}

Do bednets prevent malaria? Do vouchers increase access to treatment? Do cash transfers improve mental health? What these research questions share in common is a focus on **causal impact**—a difference in outcomes that can be attributed to a treatment, intervention, policy, or exposure. In many ways, as an applied field global health *is* the study of causal impact.

## Fundamental Challenge of Causal Inference

```{block, type='rmdplay'}
```

```{r ch4causal, echo=F}
knitr::include_url("https://warpwire.duke.edu/w/E2IBAA/")
```
[PDF slide deck](https://drive.google.com/open?id=0Bxn_jkXZ1lxubkpSdUd2M2RON1k)

In an ideal research world we could answer the question, "Do bednets prevent malaria?", by cloning you and simultaneously giving a bednet to you but not your clone. This would help us to understand what really happens in the absence of the intervention because the only difference between you and your clone would be that one of you received the intervention.[^ceteris] 

[^ceteris]: In econometrics you might see this referred to as *ceteris paribus* conditions, or *other things equal*.

Of course we don't have clones, and we can't *simultaneously* give you a bednet and not give you a bednet. We only get to observe what happens to you, not a clone of you who did not receive the intervention. So we have to ask, hypothetically, what would have happened if you had not been given a bednet. This hypothetical situation—*what would have happened in the absence of the intervention*—is referred to as the **counterfactual** (or "potential outcome" in the language of the [Neyman–Rubin causal model](https://en.wikipedia.org/wiki/Rubin_causal_model)). 

Not being able to observe the counterfactual directly is the so called "fundamental challenge of causal inference". So you could also say that this is the primary reason we need books about research designs. Much of what follows in this book deals with strategies for causal inference in the absence of a true counterfactual.

### UNDERSTANDING CAUSAL RELATIONSHIPS

Humans like you and me have a pretty decent understanding of cause and effect—hand touch fire, fire hot, fire burn hand. Philosopher humans, on the other (unburnt) hand, have spent centuries convincing us that causality is actually much more complicated than it might seem on the surface. They did a good job because causal inference is a vibrant field of study today, and researchers continue to develop new techniques for drawing causal inferences from experimental and non-experimental data. Let's review some of the basics.     

#### Causes{-}

In his book *Causal Inference in Statistics*, computer scientist Judea Pearl [-@pearl:2016] provides a simple definition of **causes**: "A variable X is a cause of a variable Y if Y in any way relies on X for its value". The phrase "in any way" is a reminder that most of the causal relationships we investigate in global health are not deterministic and effects can have more than one cause. 

Think about it this way: you give an experimental treatment to 100 people suffering from a disease and only 60 get better. If the causal relationship between the drug and disease state were deterministic, all 100 patients would have recovered. This is not what happened, however. The causal relationship only increased the probability that the effect would occur.

#### Effects{-}

**Causal impact** is the difference in counterfactual outcomes (aka, "potential outcomes") caused by some exposure, program, intervention, or policy. Sounds simple enough, but we're back to our fundamental problem: we can only observe *one* counterfactual outcome for an individual; we don't get to observe someone in two states simultaneously, e.g., treatment *and* control. This means we can't observe an effect of the program on an *individual*. We have to turn instead to groups of individuals. The best we can do is hope to infer the counterfactual by comparing some people who get some treatment to other people who do not.[^otherunits]

[^otherunits]: We could also talk about effects on other units like schools, clinics, etc, but it's easier to think about "subjects" as being people.

```{block, type='rmdtip'}
Most often we think about comparing two different sets of people who who exist in either a treatment or an intervention group, but the logic also extends to (a) more than two groups (aka, study arms) and (b) just one group of people observed at different time points.

"But I thought you said an individual like me can't exist in two states at once!" 

That's correct. We can only observe someone in one state (e.g., treatment *or* control), but we could chose to compare YOU *before* you receive a treatment to YOU *after* you receive a treatment. This is a "pre-post" or "before/after" comparison. We'll talk more about specific designs soon.
```

The most common estimate of causal impact is the **average treatment effect** (ATE). We can't observe an effect of X on Y for any specific individual (who can only exist in one state at a time), but we can determine if X causes Y *on average*. This is possible because the average difference in potential outcomes (which we can't observe) is equal to the difference of averages. The following graphic might help.[^egapfigure]

[^egapfigure]: This figure is based on [an illustration](https://raw.githubusercontent.com/egap/methods-guides/master/causal-inference/PO.jpg) created by egap. See their [helpful guide to causal inference](http://egap.org/methods-guides/10-things-you-need-know-about-causal-inference).    

```{r potentialoutcomes, fig.cap="Average causal effects can be estimated even though individual effects cannot be observed.", echo=F}
knitr::include_graphics("images/potentialoutcomes.png", dpi = NA)
```

Panel A shows hypothetical results when all subjects are assigned to treatment `Y(1)` or control `Y(0)`. There are two data points for each person corresponding to their hypothetical potential outcomes (remember that in reality we can only observe one point per person since it's not possible to be in two states at once). Both sets of points have an average value, depicted by the dashed lines that you see in Panel A and Panel C. 

In the middle Panel B, the differences between each pair of outcomes in A are plotted as individual effect sizes (e.g., `1.0-(-1.5)=2.5` for person 6). The dashed green line depicts the average causal effect. Notice that this average of individual differences in B is equal to the difference in averages in Panel C.

The point is that we cannot observe effects on individuals since we cannot measure *both* potential outcomes for any one person; however, we can estimate the average causal effect by comparing the average value from a group of people who receive the intervention to the average value from a group of people who do not. 

#### Causal relationships{-}

OK, so we've established that it's possible to estimate the average difference between two groups, but can we claim that this difference is a valid estimate of the causal impact of X on Y? In other words, how do we know that X and Y causally related? Shadish et al. [-@scc] point to three characteristics of causal relationships that we should be on the lookout for:

1. The cause is related (aka, associated) to the effect.
2. The cause comes before the effect.
3. There are no *plausible* alternative explanations for the effect aside from the cause.

Condition #1 is easy to establish. Is X correlated with Y? In fact it's so easy to establish that someone came up with the maxim, "correlation does not prove causation", to remind us that the burden of proof is greater than the output of `correlate x y` or `cor(x, y)`, or whatever command your favorite statistical software package would have you run. But it's a start.

Condition #2 is a bit harder to demonstrate conclusively because X and Y might be correlated, but maybe the causal relationship runs in the opposite direction—maybe Y causes X. Correlations don't tell us which comes first, X or Y.

Let's take malaria and poverty as an example. Jeffrey Sachs and Pia Malaney [-@sachs:2002] published a paper in *Nature* in which they wrote:

> As a general rule of thumb, where malaria prospers most, human societies have prospered least...This correlation can, of course, be explained in several possible ways. Poverty may promote malaria transmission; malaria may cause poverty by impeding economic growth; or causality may run in both directions.

Condition #3 is the trickiest of all: ruling out plausible alternative explanations. As Sachs and Malaney note, the literature on poverty and malaria has not found a way to do so conclusively. They write that it's "possible that the correlation [between malaria and poverty] is at least partly spurious, with the tropical climate causing poverty for reasons unrelated to malaria." The authors are proposing that climate is a potential cause of both poverty and malaria. If true, that would make climate a confounding (aka, lurking) variable that accounts for the observed relationship between poverty and malaria. 

## Threats to Internal Validity

The possibility of plausible alternative explanations is what keeps researchers up at night, particularly non-experimentalists. They are always on the lookout for threats to making valid causal inferences—aka, threats to internal validity.

The ["randomistas"](http://www.wsj.com/articles/the-anti-poverty-experiment-1433517539), on the other hand, tuck themselves in early after a glass of warm milk knowing that random assignment will generally make plausible alternative explanations implausible. To be sure, the randomistas will have bias-filled nightmares on occasion when they learn that an experiment did not quite go as planned, but they are generally heavy sleepers.

You'll recall that internal validity is Campbell's [-@campbell:1957] notion about whether an observed association between X and Y represents a causal relationship. If X comes before Y, and if there are no other plausible explanations for the covariation between X and Y then causal inference about X and Y is valid. Threats to causal inference are threats to internal validity. Shadish, Cook, and Campbell [-@scc] outlined nine primary reasons why it might not be valid to assume a relationship between X and Y is causal. 

<br>

```{r threats, echo=F}
threats <- data.frame(t=c("**Ambiguous temporal precedence**", "**Selection**", "**History**", "**Maturation**", "**Regression**", "**Attrition**", "**Testing**", "**Instrumentation**", "**Additive and interactive effects**"),
d=c("Lack of clarity about which variable occurred first may yield confusion about which variable is the cause and which is the effect.", "Systematic differences over conditions in respondent characteristics that could also cause the observed effect.", "Events occurring concurrently with treatment could cause the observed effect.", "Naturally occurring changes over time could be confused with a treatment effect", "When units are selected for their extreme scores, they will often have less extreme scores on other variables, an occurrence that can be confused with a treatment effect.", "Loss of respondents to treatment or to measurement can produce artifactual effects if that loss is systematically correlated with conditions.", "Exposure to a test can affect scores on subsequent exposures to that test, an occurrence that can be confused with a treatment effect.", "The nature of a measure may change over time or conditions in a way that could be confused with a treatment effect.", "The impact of a threat can be added to that of another threat or may depend on the level of another threat."))
names(threats) <- c("Threats", "Definitions")

knitr::kable(threats, format = "html", 
caption = 'Threats to internal validity. Source: Shadish et al. (2002), http://amzn.to/2cBaAM1.'
) %>%
  html_table_width(c(300,300))
```

### AMBIGUOUS TEMPORAL PRECEDENCE

Correlational studies can establish that X and Y are related, but often it's not clear that X occurred before Y. Uncertainty about which way a causal effect might flow is referred to as **ambiguous temporal precedence**—or simply the chicken and egg problem.

Sometimes the direction is clear because it's not possible for Y to cause X. For instance, hot weather (X) might drive ice cream sales (Y), but ice cream sales (Y) cannot cause the temperature to rise (X). 

Most relationships we care about in global health are not so clear, however. Take bednet use and education as an example. Does bednet use prevent malaria and allow for greater educational attainment? Or does greater education lead to a better understanding and appreciation of the importance of preventive behaviors like bednet use?[^bi]

[^bi]: We won't consider possible bidirectonal (reciprocal) causation in this book. 

### SELECTION

As we discussed earlier, the fundamental challenge of causal inference is that we cannot observe the counterfactual directly. So often we look to compare a group of people who were exposed to the potential cause to a group of people who were not exposed. No matter how hard we try to make sure that these two groups of people are equivalent *before* the treatment occurs, there can be observable and unobservable ways in which these groups differ. These differences represent **selection** bias, a threat to internal validity. 

For instance, Bradley et al. [-@bradley:1986] compared parasite and spleen rates among bednet users and non-users in The Gambia and concluded that bednets had a "strong protective effect" against malaria; however, the authors also observed that bednet use and malaria prevalence were also associated with ethnic group and place of residence. This makes ethnic group and place of residence confounding variables—plausible alternative explanations for the relationship between bednet use and malaria.

Identifying selection bias and trying to account for it in the analysis is like squashing an ant on your countertop. You got that one, good for you, but there are probably many more hiding in the walls. You just can't see them. It's the same with selection threats. You might measure some of them, but many confounding variables will probably go unobserved. The only way to be certain that you are free of such threats is to randomly assign people to conditions.

### HISTORY

**History** threats pick up where selection threats leave off. Whereas selection threats are reasons that the groups might differ *before* the treatment occurs, history threats occur between the start of the treatment and the posttest observation. 

Before/after studies (aka, pre-post studies) are particularly susceptible to history threats. In these designs researchers assess the same group of people before and after some intervention. There is no separate control or comparison group. The assumed counterfactual for what would have happened in the absence of the intervention is simply the pre-intervention observation of the group.

Okabayashi et al. [-@okabayashi:2006] is a good example. In this study, the researchers conducted a baseline survey and then began a school-based malaria control program. Nine months later, they conducted a post-program survey with the same principals, teachers, and students. On the basis of the pre-post differences they observed, the authors concluded the educational program had a positive impact on preventive behaviors. For instance, student-reported use of bednets ("always") increased from 81.8% before the program to 86.5% after the program.

It's possible that the program changed behavior, but without evidence to the contrary, it's also possible that something else was responsible for the change. Maybe another program was active at the same time. Maybe there was a marketing campaign for a new type of bednet just hitting the market. Maybe the posttest occurred during the rainy season when people know the risk of malaria is greater. These are all examples of possible history threats that could invalidate causal inference about the impact of the program on behavior change.

### MATURATION

Single group designs like Okabayashi et al. [-@okabayashi:2006] are also subject to **maturation** threats. The basic issue is that people, things, and places change over time, even in the absence of any treatment. This is easy to imagine if you picture the learning that happens in one year of school for young kids. Comparing kids at the end of the year to their younger selves a year earlier and making a causal inference about some program or intervention is problematic because kids gain new cognitive skills as they age. Maybe the change you observe is due to a specific program or intervention, or maybe it is just the passage of time. Without a comparison group of similar aged kids it can be hard to know the difference.

### REGRESSION ARTIFACTS

This threat occurs most often when people are selected for a study because they have very high or very low scores on some outcome. It's often the case that scores will be less extreme at retest, independent of any intervention. This statistical phenomenon is called **regression to the mean**. It happens because of measurement error and imperfect correlation. 

### ATTRITION

**Attrition** happens when study participants do not participate in outcome assessments. When attrition is uneven between study groups, it can be described as systematic attrition. Just like selection bias makes groups unequal at the beginning of a study, *attrition bias makes groups unequal at the end of the study* for reasons other than the treatment under investigation.

For instance, let's say that researchers recruit depressed patients to take part in an RCT of a new psychotherapy that is delivered over the course of 10 weekly sessions. If the most depressed patients in the treatment group drop out because the schedule is too demanding, then the analysis would compare the control group (with the most depressed patients still enrolled) to a treatment group that is missing the most depressed patients.[^notRTTM] It would appear as if the treatment group got better on average, but part or all of the observed treatment effect would be due to attrition of the most depressed patients from the treatment group, not because of the treatment.

[^notRTTM]: Recruiting depressed patients sounds like it could be a situation of regression to the mean, but there's no cause for concern because there is a control group that would experience the same phenomenon.

### TESTING

Repeated administrations of the same test can have an effect on test scores, independent of the program that the test is designed to evaluate. For instance, practice can lead to better performance on cognitive assessments, and this improved performance can be mistaken as a treatment effect if there is not a comparison group. **Testing** threats decrease as the interval between administrations increases.

### INSTRUMENTATION

Testing threats describe changes to how participants perform on tests over time due to repeated administrations. When the tests themselves change over time we call this an **instrumentation** threat. For instance, if a study uses different microscopes or changes measurement techniques for the posttest assessment, it's possible that differences in blood smear results could be incorrectly attributed to an intervention.

### ADDITIVE AND INTERACTIVE EFFECTS

Unfortunately, a study can be subject to more than one of these threats to internal validity. It's possible for threats to work in opposite directions, or to interact and make matters a lot worse. For instance, if Okabayashi et al. [-@okabayashi:2006] had decided to compare students who received the program to students from another part of the country who did not receive the program, they might have observed a selection x history threat. The two groups of students might have been different to begin with (selection) and might have had different experiences over the study period unrelated to their treatment or non-treatment status (history).

## Research Designs to Estimate Causal Impact

```{r cyoa, fig.cap="Research design choose your own adventure. PDF download, https://drive.google.com/open?id=0Bxn_jkXZ1lxuWkhFcTUzdWVkZ0E", echo=F}
knitr::include_graphics("images/cyoa.png", dpi = NA)
```

### EXPERIMENTAL DESIGNS
	
If given the choice, many (if not most) researchers would choose an experimental design to estimate causal impact. Experiments are subject to bias when things don't go as planned (e.g., systematic attrition), but a good experiment is subject to fewer threats to internal validity compared to every other design for two main reasons:

1. The cause always comes before the effect in an experiment (and quasi-experiment) because the treatment is "manipulated"; some people get the treatment but others don't. After the treatment is administered to some people, outcomes are observed. Cause before effect.

2. Random assignment makes plausible alternative explanations implausible. This is the big one. Whereas other designs require stronger assumptions about selection threats, experiments dismiss them by distributing observable and unobservable differences approximately equally across study arms.

```{r desexp, fig.cap="Basic experimental design", echo=F}
knitr::include_graphics("images/designs-exp.png", dpi = NA)
```

#### Example{-}

An important global health policy question that has been studied using experimental and quasi-experimental methods is the impact of user fees on the adoption of health goods, such as bed nets. Advocates of fees argue that free distribution is not sustainable and leads to waste when people who don't need or want the goods are recipients. There is also an argument that people only value what they pay for, so removing fees will make people less likely to use goods like bed nets. 

The flip side is that the provision of some health goods, in economics-speak, creates "positive externalities" and should therefore be financed with public dollars. What this means is that some interventions have spillover effects whereby people who are not treated still experience some indirect effect. A good example of a spillover effect is vaccines and the resulting [herd immunity](https://en.wikipedia.org/wiki/Herd_immunity). Hawley et al. [-@hawley:2003] showed a similar protective effect of ITN use on child mortality and other malaria-related outcomes among households without ITNs that were located within 300 meters of households with ITNs.

So we know that there is evidence that ITNs have direct [@phillipshoward:2003] and indirect benefits. The research problem is then how to increase coverage and use of nets. Is free distribution the best strategy, or should users have to spend something to get a bed net that might retail for a price that is out of reach for many poor households? In other words, should ITNs be free or subsidized? 

Cohen and Dupas [-@cohen:2010] used an experimental design to study this question in Kenya where malaria is the leading cause[^leading] of morbidity and mortality. The authors randomly assigned 20 prenatal clinics in an endemic region to 1 of 5 groups: a control group that did not distribute ITNs, a free distribution group, a group that charged 10 Ksh per ITN (97.5% subsidy), a group that charged 20 Ksh (95% subsidy), and a group that charged 40 Ksh or about $0.60 USD (90% subsidy). When units like clinics, schools, and villages are randomized, we refer to the design as a **cluster-randomized trial**, or CRT. 

[^leading]: KEMRI (n.d.). Kenya malaria fact sheet. Available at [http://www.kemri.org/index.php/help-desk/search/diseases-a-conditions/29-malaria/113-kenya-malaria-fact-sheet](http://www.kemri.org/index.php/help-desk/search/diseases-a-conditions/29-malaria/113-kenya-malaria-fact-sheet).

The authors followed up a subset of pregnant women over time and found that those who paid a subsidized price were no more likely to use the bed nets than women who received one for free. They also found that the increase in price from $0 to $0.60 USD reduced demand for ITNs by 60%. This implies that the cost-sharing model of having women pay something for ITNs will reduce coverage. This is bad for the women who forgo a net purchase because of the direct prevention effects of ITNs, but we know from Hawley et al.'s work that it's also bad for the community since ITNs have spillover effects. Cohen and Dupas conclude that free distribution would ultimately save more child lives.

### QUASI-EXPERIMENTAL DESIGNS

As great as experiments are for mimicking the counterfactual, it's not always logistically possible, politically feasible, or ethically justified to run an RCT. Most often, researchers have to infer causal inference from non-experimental data. How this is done in practice is shaped in part by disciplinary traditions.

For instance, psychologists trained in the tradition of Campbell tend to focus on design choices you can make *before* a study is launched to improve causal inference by ruling out alternative explanations [@scc]. This is the idea of the *primacy of control by design*—try to prevent confounding or at least investigate the plausibility of alternative explanations by adding design elements like more pre-test observations and comparison groups.

Economists have a similar preference for strong designs, but their approach to causal inference tends to focus more on the analysis that comes *after* data collection. Whereas psychologists might ask about threats to internal validity, economists are likely to ask "what's your identification strategy?". Econometricians Angrist and Krueger [-@angrist:1999] defined **identification strategies** as "the combination of a clearly labeled source of identifying variation in a causal variable and the use of a particular econometric technique to exploit this information." For instance, economists spend a lot of time thinking about the returns on schooling. The most common identification strategy to estimate the impact of schooling (the proposed causal variable) uses regression to control for potential confounds.

In addition to regression, the econometrics (or 'metrics, if you are cool) toolkit for non-experimental data also includes instrumental variables, regression discontinuity, and differences-in-differences [@angrist:2015]. I'll add interrupted time series to the list. Psychologists (and others) would label these **quasi-experimental** designs because they involve some manipulable cause that occurs before an effect is measured but *lack random assignment*. 

```{r desquasi, fig.cap="Common quasi-experimental designs", echo=F}
knitr::include_graphics("images/designs-quasi.png", dpi = NA)
```

#### Example{-}

Agha et al. [-@agha:2007] used a quasi-experimental design to estimate the impact of a [social marketing](https://en.wikipedia.org/wiki/Social_marketing) intervention on ownership and use of ITNs in rural Zambia. Nets that commonly sold for USD $27 were subsidized and sold for $2.50 at public health clinics. Neighborhood health committees were established and 600 volunteer "promoters" were trained to teach residents about malaria and encourage them to purchase the nets.

To estimate the impact of the intervention, the authors analyzed data from post-intervention surveys in three intervention and two comparison districts. This study design was quasi-experimental because the districts were *not* randomized to the intervention or control arms. 

```{r agha, fig.cap="Source: Agha et al. (2007), http://bit.ly/1MkO5a0", echo=F}
knitr::include_graphics("images/agha.png")
```

Agha and colleagues reported that ITN ownership and use was higher in intervention districts according to the post-intervention data, but were careful to avoid going 'beyond the data' to claim evidence of a causal relationship. There are several design limitations to consider here, and you will learn more about how to spot these issues as we go.

Briefly, we can note that (i) the authors did not randomize districts to study arms and (ii) no baseline (a.k.a. pre-treatment) data was collected. Experimental studies benefit from, but do not require, baseline (or pre-intervention) data because randomization usually ensures that the treatment and comparison groups are similar at the start—if enough units are randomized. But a non-randomized study like this leaves itself open to criticism without baseline data to show that the intervention and comparison districts were similar *before* the intervention was introduced. The results suggest that they were different *after* the intervention period, but we can't be sure this was caused by the intervention itself.

Given the limitations, how should we view the results? If this was one of the first studies on the topic, we would view it as a starting point that would encourage more rigorous investigations. As part of a larger body of evidence, however, it would probably be passed over in **systematic reviews** and **meta-analyses**—studies of studies—because of the limitations of the design for causal inference.

### OBSERVATIONAL DESIGNS

Epidemiologists are typically associated with observational designs such as cross-sectional surveys, case-control studies, and cohort studies, though plenty of epidemiologists design and implement RCTs. [They do not typically distinguish between quasi-experimental and other non-experimental (or observational) designs like case-control or cohort studies.]

```{r desobs, fig.cap="Common observational designs", echo=F}
knitr::include_graphics("images/designs-obs.png", dpi = NA)
```

Observational studies can yield important insights about cause and effect, but they have limitations. You've probably heard that correlation does not equal causation. For instance, did you know there is a nearly [perfect correlation](http://www.tylervigen.com/view_correlation?id=7) between the per capita consumption of cheese and the number of people who have died by becoming tangled in their bedsheets? (If you just put down the hunk of aged cheddar you were eating, please keep reading this book!) That said, all studies have limitations and trade offs. Designing a good study is a process of weighing scientific objectives with logistical constraints, ethical considerations, time, money, and a host of other factors. Here are some common observational designs. 

#### Cross-Sectional{-}

##### Descriptive research{-}

The goal of **descriptive research** is to characterize the population. Often this means estimating the **prevalence** of a phenomenon or disease. 20% are illiterate. 36% have an unmet need for contraception. 9% are HIV positive. Description can also be qualitative in nature (e.g., [thick description](https://en.wikipedia.org/wiki/Thick_description)).

Just about every study will have some descriptive element. Some studies are primarily descriptive. A good example are the [Demographic and Health Surveys](http://www.dhsprogram.com/), more commonly referred to as DHS surveys (yes, "surveys" is redundant). Every student of global health should come to know what the DHS Program has to offer. The program is funded by the [U.S. Agency for International Development](http://www.usaid.gov/) (USAID), and registered users can request access to data from more than 300 surveys conducted in 90+ countries.

A DHS survey is also an example of a **cross-sectional** study. These are typically one-off surveys but can include other forms of data collection. The key is that it's a snapshot. The goal is often description but might also include correlation. Cross-sectional studies are differentiated from **panel** or **longitudinal** studies by their participants; the latter include the same research participants (**sample**) over time in multiple studies, whereas cross-sectional studies only include a particular sample once. So even though the DHS Program will conduct a new survey in a country every five years or so, they always recruit a new sample of participants (a.k.a. "successive independent samples"). This makes the DHS surveys cross-sectional rather than panel or longitudinal in design.

```{block, type='rmdpuzzle'}
DHS surveys are a good example of **demographic research**. Demographers contribute to and use data sources like DHS surveys and national population and housing censuses to understand more about population size, structure, and change (e.g., birth, death, migration, marriage, employment, education).

Many countries strive to conduct a [census](https://en.wikipedia.org/wiki/Census), or an enumeration of all citizens, every 10 years. The [United Nations Statistics Division](http://unstats.un.org/unsd/default.htm) and the [United Nations Population Fund](http://www.unfpa.org/census) (UNFPA) provide technical support (a.k.a., help) to countries preparing for, conducting, and analyzing a national population and housing census. These two organizations, in partnership with the [United Nations Children's Fund](http://www.unicef.org/) (UNICEF), maintain [CensusInfo](http://www.censusinfo.net/), a database of global census data.
```

Here is the relevant table from the 2014 Kenya DHS Key Indicators Report for describing the prevalence of ITN use.[^dhsprocess] This is a typical DHS cross tabulation (or crosstab) of the results. In this example, the percentage of children under the age of 5 that slept under an insecticide treated net the previous night in Kenya was 54.1%. This descriptive data is further disaggregated by residence and wealth quintile as is typical for DHS tables.[^rep]

[^dhsprocess]: The DHS Program runs several types of surveys, with the DHS surveys being the most well known. A DHS survey takes an average of 18-20 months to complete. Preliminary results are released about a month after the end of data collection, but it can take up to a year to release the final report and data. See here for more details about the DHS process: [http://dhsprogram.com/What-We-Do/Survey-Process.cfm](http://dhsprogram.com/What-We-Do/Survey-Process.cfm).

[^rep]: As we will discuss later, DHS surveys include enough people to be **representative** for different subgroups, such as urban and rural settings or wealth quintiles (the rich, the poor, and everyone in between). 

```{r kdhs, fig.cap="Source: Kenya 2014 DHS Key Indicators Report, http://bit.ly/1g4NYS5", echo=F}
knitr::include_graphics("images/kenyaitn.png")
```

The data summarized in this table describes the problem of bed net use. Descriptive questions are well-suited for **needs assessments**. Before we can design a program or policy to increase bed net usage, for instance, we must to understand the need. In Kenya, almost half of children under 5 are not sleeping under insecticide treated nets according to the DHS. This is a particular concern for children living in areas of high risk. 

##### Correlational research{-}

This descriptive information sheds light on programmatic and policy priorities, but we have to go beyond describing the problem to make a difference.

A helpful next step is often to build on descriptive insights by attempting to predict or explain the behavior or phenomenon. For instance, Noor et al. [-@noor:2006] asked a correlational research question (edited below) about the factors associated with net use among children under the age of 5: 

> Are wealth, mother's education, and physical access to markets associated with the use of nets purchased from the retail sector among rural children under five years of age in four districts in Kenya?

**Correlational research** asks questions about the relationship (a.k.a. association) between two or more variables. In this case, ITN use and a variety of potentially influential factors, such as household wealth and a mother's education level.

Noor and colleagues reported that only 15% of children in the rural study sample slept under a net the previous night—a much lower percentage than the national prevalence reported by recent DHS surveys. As shown in the table below, they also found that several factors were associated with higher odds of bed net use, including: greater household wealth, living closer to a market center, not having older children present in the household, having a mother who is married and not pregnant, being younger than 1 year old, and having an immunization card.

```{r noor2, fig.cap="Source: Noor et al. (2006), http://bit.ly/1HoltVo", echo=F}
knitr::include_graphics("images/noor2006t4.png")
```

##### Cohort{-}

A **cohort** is a group of people recruited because they share something in common. In a **prospective cohort** study, participants without the outcome of interest are recruited and followed into the future for a period of time to see who develops the outcome. 

For instance, @lindblade:2015 conducted a prospective cohort study in Malawi to test the efficacy of ITNs in an area of moderate resistance to pyrethroids, a common class of insecticide. They followed a cohort of 1,199 healthy children (i.e., no malaria) aged 6-59 months for one year and found that the incidence of malaria infection over this time was 30 percent lower among ITN users compared to non-users. 

```{block, type='rmdpuzzle'}
The **exposure** in this study was bednet use the night before the study team visited the household: ITN user, untreated net user, or no net. This is a bit confusing because using bednets is protective. Most often we read about exposures that are bad, like smoking. The research question is the same in both cases, however: does the emergence of the outcome differ by exposure status?
```

This is promising, but the study design has limitations. One important limitation is that the children were not randomized to ITN access. So it could be the case that children who used the ITNs were somehow different from the children who did not use the ITNs. This is a potential selection bias, a threat to internal validity. You'll learn more about such threats in a later chapter. The basic challenge for causal inference is that the design does not rule out the possibility that something other than ITN use accounted for the reductions in malaria infections.

A **retrospective cohort** study looks similar except that, by the time the researcher gets involved, the cohort has already been recruited and data collected. For instance, a researcher might use medical records to find groups of people who share many characteristics but differ in terms of some exposure (e.g., smoking). These groups are then compared to see who went on to develop the outcome.

For instance, @fullman:2013 used birth history information contained in DHS and MIS micro-data (i.e., survey data about individuals and households, not just the summary reports) to construct retrospective cohorts of children from age 1 to 59 months. They were interested in estimating the effect of ITNs and indoor residential spraying (the exposures) on child mortality (the outcome) within 59 months of birth, so they used survey data to determine if and when households were "exposed" to these prevention tools. Note that everything about this study was retrospective; the authors did not collect their own data or follow any participants over time. In the end, they found that bednets and spraying reduced malaria-related morbidity, but not child mortality.

##### Case-control{-}

Sometimes it is not possible to recruit a group of healthy people and wait to see who gets sick as you would in a prospective cohort study. Imagine having to wait a decade or more to see who develops rare diseases like gliomas. This would be a very expensive study that would need to involve thousands of people to study such a rare disease that takes time to emerge. A **case-control** study might be a better fit. In this design, researchers identify people with the disease (cases) and without the disease (controls) and ask them about *past* exposures. 

@obala:2015 did this in Kenya with 442 children hospitalized with malaria and healthy matched controls without evidence of malaria. They wanted to know why there is a high malaria burden despite high ITN coverage. The research team visited visited the home of each case and control and asked questions about ITN coverage and recent use, along with measuring the parasite burden of family members, mapping nearby potential vector breeding sites, and assessing neighborhood ITN coverage. Obala and colleagues found that ITN coverage was not correlated with hospitalizations, but consistent ITN use decreased the odds of hospitalizations by more than 70%.

As with prospective cohort designs, there is a risk of selection bias. In this case, we have to be concerned that the matching process was not perfect. The matching was done on the basis of age, gender, and village. But there could be unmeasured ways in which the cases and controls differ, which would undermine the results. 

```{block, type='rmdpuzzle'}
A case-control study looks like a retrospective cohort, but flipped: 

1. In a retrospective cohort you look to see if people with different exposures have different outcomes.

2. In a case-control study you look to see if people with different outcomes had different exposures.

Another difference is that, in a case-control study, the researcher recruits participants in the present day and asks them about historical events, whereas all data collection has already taken place in a retrospective cohort study.
```


## Share Feedback{-}

This book is a work in progress. You'd be doing me a big favor by taking a moment to tell me what you think about this chapter.

```{r CH04feedback, echo=F}
knitr::include_url("https://duke.qualtrics.com/SE/?SID=SV_2shfRWYmL7faNxP",
height="600px")
```
