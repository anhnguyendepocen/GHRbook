--- 
knit: "bookdown::preview_chapter"
---

# Indicators {#indicators}

**Indicators** are observable measures of study constructs. Part of developing a good logic model is identifing indicators for each part of the hypothesized causal chain.  To define a construct in terms of an indicator and to specify its measurement is to **operationalize** the construct. In this chapter we'll frame the discussion of how to operationalize study constructs in terms of causal chains, but the lessons apply more broadly.

## Indicators Throughout the Causal Chain

To demonstrate how to identify indicators throughout the causal chain, we'll use an example from Jokhio and colleagues [-@jokhio:2005] about the impact of training traditional birth attendants (TBA) in Pakistan on the occurrence of stillbirths, neonatal deaths, and maternal deaths. When this study was conducted in 1998, the maternal mortality ratio in Pakistan was more than 280 per 100,000 live births [@whomm:2014].[^mm2013] This represents more than 13,000 women who died giving birth.[^tragedy]

[^mm2013]: The maternal mortality ratio in Pakistan was 170 in 2013.

[^tragedy]: The tragedy in this number is that maternal mortality is preventable. Women continue to die before, during, and after childbirth because of three major delays: (i) delays in seeking healthcare; (ii) delays in reaching healthcare; and (iii) delays in receiving high quality healthcare upon reaching a medical facility [@thaddeus:1994]. The most common proximate causes of death are postpartum hemorrhage, hypertensive disorders, and sepsis [@say:2014]. 

It's hard to predict who will suffer life threatening complications, so there is debate about how to best intervene. Some argue that we should invest in interventions to increase facility deliveries so that women would be better able to access emergency obstetric care if needed. Others point to the low frequency of complications and the high prevalence of poor quality care at medical facilities as a reason that women should be supported in their decision to stay at home where the family can better support them.

At the time Jokhio and colleagues conducted this study, facility deliveries in Pakistan were rare. The authors cited descriptive studies showing that most women in Pakistan delivered at home (80%) without a skilled birth attendant (89%). Only 1 out of 20 women who experienced complications made it to a medical facility with emergency obstetric care.

Given the high prevalence of home deliveries, Jokhio et al. tested an intervention that trained traditional birth attendants—the mothers, aunts, sisters, and neighbors who already help women through childbirth but have no formal medical training—and provided them with delivery kits. The training lasted 3 days and covered topics such as checking for danger signs, conducing a clean delivery using the provided kits, and making emergency referrals. Trained TBAs were asked to visit with women at least three times during the pregnancy to look for danger signs, and then again for the delivery.

The study design was a cluster randomized trial. Seven subdisticts of a rural district were randomized to the TBA intervention or the standard of care. TBAs in subdistricts assigned to the control group did not receive any training or delivery kits. The primary outcome was reduced perinatal deaths (stillbirths and neonatal deaths) and maternal deaths. Let's think about measurement throughout this causal chain.

```{r jokhiologic, fig.cap="Logic model developed for Jokhio et al. (2005).", echo=F}
knitr::include_graphics("images/JokhioLogic.png", dpi = NA)
```

### PROCESS INDICATORS

Indicators that define inputs, activities, and outputs in a logic model can be decribed as **process indicators**. These steps in a logic model capture how a program is implemented. In short, the "M" (monitoring) in M&E.

As researchers we care about collecting good process/monitoring data in order to develop a better understanding why programs do or don't work. For instance, we might want to track program costs so that we can estimate cost-effectiveness. Or we might want to know if the intervention was delivered according to plan or not. Researchers often rely on program parnters to deliver the intervention under investigation, so issues like fidelity to treatment and compliance with study protocols are important to track closely. Let's review a few examples of process indicators that intervention researchers often care about.

#### Inputs{-}

As you'll recall from the previous chapter, inputs are the resources needed to implement the program. The most basic input of all is money, therefore one indicator is program cost.

Impact evaluations produce estimates of the effectiveness of a program or intervention. Does the program "work"? For some public health and behavioral health nerds, evidence of impact is enough because they are narrowly focused on developing and testing new interventions. Not true for policymakers who are thinking about delivering programs at scale with limited public funding; they want to know whether the intervention is *cost-effective*, not just effective.[^T4] A cost-effectiveness analysis requires close tracking of the cost of all program inputs. Jokhio et al. don't tell us about the cost of the TBA training program, other than to say the intervention was designed to be "low cost and sustainable".

[^T4]: As discussed in Chapter 1, the gap between developing evidence of effective programs and actually implementing them at scale is an example of a "T4" translational research bottleneck.

```{block, type='rmdpuzzle'}
Cost effectiveness analysis (CEA) is not the same thing as cost-benefit analysis (CBA). The latter involves putting a dollar amount to benefits, such as the benefit to society of averting a maternal death. This is hard to do and quite subjective. This is why you will come across CEA much more frequently in global health. The typical calculation is the effect size divided by the costs. There is no effort to put costs and effects on the same dollar metric. See the ["WHO guide to cost-effectiveness analysis"](http://www.who.int/choice/publications/p_2003_generalised_cea.pdf) for additional guidance.
```
#### Activities/Outputs{-}

##### Treatment fidelity{-}

**Treatment fidelity** is a measure of how closely the actual implementation of a treatment or program reflects the intended design. The TBA intervention studied in Jokhio et al. included a 3-day training and the provision of delivery kits. If a trainer decided to skip portions of the training or knock off a day, the program would not be delivered as intended (aka, without fidelity to the treatment). The consequence of low treatment fidelity is usually an attenuation (aka, shrinking) of treatment effects. This is a threat to internal validity. If the study shows no effect but treatment fidelity is low, we can't be confident in the null result. *Implementation failure* rather than *theory or program failure* could be to blame. Low fidelity is also a threat to external validity because it isn't possible to truly replicate the study.

The first step in developing a measure of fidelity is to identify what constitutes the intervention. Jokhio et al. did not discuss fidelity, but we can develop a basic plan based on what we know. The study involved training TBAs on the following topics:

* giving advice on antepartum, intrapartum, and postpartum care; 
* how to conduct a clean delivery; 
* how to use the disposable delivery kit; 
* when to refer women for emergency obstetrical
care; 
* and care of the newborn. 

There are two levels of training we could evaluate: the quality of the training and the resulting knowledge of the TBAs who were trained.

First, we want to make sure that the people training the TBAs (i) adhere to the training manual and (ii) correctly present all of the training material. We might do this by creating a TOT fidelity checklist that can be used to assess adherence and competence [@breitenstein:2010]. For instance:

* **Adherence**
	* trainer reviews didactic material on conducting a clean delivery
	* trainer facilitates the demonstration activity on how to use the disposable delivery kit
* **Competence**
	* trainer correctly explains the key danger signs to look for during the antepartum period
	* trainer demonstrates proper use of the delivery kits

Second, we want to know that the TBAs learned something from the training. This could be as simple as administering a knowledge and practical test at the end of the training. To continually monitor fidelity over time, we could arrange to observe or record TBA interactions with patients and evaluate fidelity with another checklist. Depending on the situation, we could also use "mystery clients"—confederates who pose as real clients—to evaluate fidelity without the target's knowledge.

##### Treatment compliance{-}

**Treatment compliance** is a measure of the extent to which people (or units) were treated or not treated according to their study assignment. In a randomized trial, people (or other units like schools and clinics) are randomly assigned to different study arms. In Jokhio et al., subdistricts were randomly assigned to the TBA intervention group (treatment) or the no program group (control). Sometimes plans don't work out and people or units are "non-compliant" with these assignments. For instance:

*  Some people assigned to the *treatment* group are never treated or only partially treated. Maybe some TBAs never showed up for the training program or stopped attending before the end.   

*  Some people assigned to the *control* group receive the treatment despite their assignment to the inactive control group. An example would be if TBAs in control subdistricts heard about the nearby training and decided to attend.

Just like low-treatment fidelity, non-compliance with the study protocol can attenuate treatment effects. We'll discuss these threats more in the chapter on experimental designs. The take home point for now is that close tracking of outputs can be critical for your analysis of treatment effects.

### OUTCOME/IMPACT INDICATORS

While process indicators are important to track for research purposes, researchers tend to spend the most time and effort defining measurement strategies for study outcomes and impacts. Jokhio et al. evaluated the effect of the TBA intervention on a set of outcomes that included the occurrence of major complications of pregnancy and referral to emergency obstetric care. The authors also examined the impact of the intervention on maternal mortality. 

Jokhio et al. reported that the intervention reduced the odds of hemorrhage by 39%, but they did not provide the definition of postpartum hemorrhage used in their study. Commonly this is defined as vaginal bleeding greater than 500 mL after vaginal delivery or 1000 mL after cesarean delivery [@knight:2009]. Accurate measurement of postpartum hemorrhage is a challenge, but that's a topic for the next chapter.

Jokhio et al. also reported a 26% reduction in maternal deaths, but the estimate was not very precise.[^mm] The authors defined maternal deaths as "deaths during pregnancy and up to 6 weeks postpartum, excluding those known to have been due to injury or accident".

[^mm]: The study was only designed to detect a reduction in maternal deaths of 90%, so it is not surprising that they did not find a statistically significant effect. This indictor made sense in the theory of change, however: better equipped TBAs who are present at deliveries will reduce the incidence of major complications that are most likely to lead to maternal deaths; better access to emergency referrals will have the same life saving effect. So no definitive evidence about the impact of the intervention on maternal mortality, but large effects on the intermediate outcomes supports the underlying theory of change. 

## Selecting Good Indicators

When designing a new program, the common advice is to create [SMART](https://en.wikipedia.org/wiki/SMART_criteria)™ targets and objectives:

----------------  --------------------------
**S**ecific       clearly defined
**M**easurable    able to be quantified
**A**ttainable    target must be realistic
**R**elevant      related to the construct
**T**ime-bound    observed at specific times
----------------  --------------------------

Measuring progress against SMART objectives and targets should be done through the use of DREAMY™ indicators. Here's what I think makes an indicator DREAMY:

----------------  --------------------------
**D**efined       clearly specified
**R**elevant      related to the construct
**E**xpedient     feasible to obtain
**A**ccurate      valid measure of construct
**M**easurable    able to be quantified
customar**Y**     recognized standard
----------------  --------------------------


### USE DREAMY INDICATORS™

Jokhio and colleagues tested an intervention designed to make motherhood safer. The ultimate indicator of safe motherhood is reduced maternal mortality. Let's put this indicator to the DREAMY test. 

##### Defined{-}

The first step to becoming a good indicator is having a clear definition. Jokhio et al. used the following definition of a maternal death: 

> Maternal deaths were defined as death of the mother during pregnancy, delivery, and up to six weeks postpartum, excluding deaths known to have been due to injury or accident.

##### Relevant{-}

Maternal deaths are clearly relevant to the construct of safe motherhood. Perceptions about health facility quality might not be as relevant, however. 

##### Expedient{-}

Data on maternal deaths are not easy to collect at the national level, but the study authors devised a good measurement plan (the topic of the next chapter). Jokhio et al. relied on Lady Health Workers—a cadre of educated women with 3 to 6 months of training in primary health care and family planning—to collect oral reports on the cause of death from relatives, neighbors, and TBAs.

##### Accurate{-}

By using a definition that excludes deaths due to injuries and accidents, the authors focus on the causes of death that their intervention seeks to prevent. A reduction in these deaths would be a valid indicator of safe motherhood.

##### Measurable{-}

Maternal deaths can be quantified, but without a registry of death certificates indicating the cause of death, it's easy to make mistakes. Jokhio et al. relied on Lady Health Workers to obtain "oral reports" on the cause of death from relatives, neighbors, and TBAs. The authors do not use the term "[verbal autopsy](https://en.wikipedia.org/wiki/Verbal_autopsy)", but that is the inferred method. In this particular study, a VA is a reasonable choice because the timing of death was ascertainable for all women. It is possible that some deaths due to accident or injury were incorrectly labeled as maternal deaths, but there is no way to know.

##### customarY{-}

Jokhio et al.'s definition of maternal mortality will look familiar to folks who study reproductive health issues because it largely follows the authoritative definition that comes from a set of classification standards known as the ["International Statistical Classification of Diseases and Related Health Problems"](http://www.who.int/classifications/icd/en/), or ICD. According to the latest version, the ICD-10:[^icd9]

> A maternal death is the death of a woman while pregnant or within 42 days of termination of pregnancy, irrespective of the duration and the site of the pregnancy, from any cause related to or aggravated by the pregnancy or its management, but not from accidental or incidental causes.

[^icd9]: The ICD-9 definition—which would have been the standard at the time of the study—is very similar. For more information, see [http://1.usa.gov/1JF0vnv](http://1.usa.gov/1JF0vnv).

### USE INTERNATIONAL STANDARDS

#### WHO Global Reference List{-}

Whenever possible, you should seek out standard indicators and follow existing definitions and calculation methods. The WHO publishes a *Global Reference List* of the 100 core health indicators [@whocore:2015]. The 2015 version categorizes the indicators several ways:

* domain
	* health status
	* risk factors
	* service coverage
	* health systems (service delivery, quality of care, health financing, essential medicines, the health workforce, health information)
* subdomains
	* communicable diseases (HIV/AIDS, sexually transmitted infections, tuberculosis, malaria, neglected tropical diseases, outbreaks, epidemic diseases)
	* reproductive, maternal, newborn, child and adolescent health (including sexual health and reproductive rights and immunization), 
	* noncommunicable diseases (including chronic disease, health promotion, nutrition, mental health and substance abuse)
	* injuries and violence and the environment
* levels of the results chain framework

Here is the full list of indicators organized by steps in a logic model. 

```{r core100, fig.cap="WHO 100 core health indicators. Source: http://bit.ly/1NgGeLh", echo=F}
knitr::include_graphics("images/grl.png", dpi = NA)
```
#### Sustainable Development Goals{-}

```{r sgds, fig.cap="Sustainable Development Goals. Source: http://bit.ly/2cuDpWN.", echo=F}
knitr::include_graphics("images/sdgs.png", dpi = NA)
```
If 100 is not enough indicators for you, try the United Nations [Sustainable Development Goals](https://sustainabledevelopment.un.org/). There are 230 indicators to measure 169 targets for 17 goals! The SDG indicators even get their own [website](http://unstats.un.org/sdgs/).

**Goal 3** is to "Ensure healthy lives and promote well-being for all at all ages". **Target 3.1** relates to maternal mortality:

> By 2030, reduce the global maternal mortality ratio to less than 70 per 100,000 live births

There are two indicators to measure progress against this target:

* **Indicator 3.1.1**: Maternal mortality ratio
* **Indicator 3.1.2**: Proportion of births attended by skilled health personnel

In the [meta-data file for Indicator 3.1.1](http://unstats.un.org/sdgs/metadata/files/Metadata-03-01-01.pdf), the maternal mortality ratio (MMR), is defined as:

> The number of maternal deaths during a given time period per 100,000 live births during the same time period. It depicts the risk of maternal death relative to the number of live births and essentially captures the risk of death in a single pregnancy or a single live
birth.

A maternal death is defined as:

> The annual number of female deaths from any cause related to or aggravated by pregnancy or its management (excluding accidental or incidental causes) during pregnancy and childbirth or within 42 days of termination of pregnancy, irrespective of the duration and site of the pregnancy, expressed per 100,000 live births, for a specified time period.

### Additional Resources on Indicators{-}

```{r addresources, echo=F}
addres <- data.frame(ar=c(
  "**Malaria**",
  "",
  "**HIV/AIDS**",
  "**TB**",
  "**Family Planning**"
),
tp=c("Roll Back Malaria (2013). [Household Survey Indicators for Malaria](http://www.malariasurveys.org/documents/Household%20Survey%20Indicators%20for%20Malaria%20Control.pdf).",
     "Measure Evaluation (2016). [Monitoring and Evaluation of Malaria Programs](http://www.cpc.unc.edu/measure/resources/publications/ms-16-110/at_download/document).",
     "WHO (2015). [Consolidated Strategic Information Guidelines for HIV in the Health Sector](http://www.who.int/hiv/pub/guidelines/strategic-information-guidelines/en/).",
     "WHO (2015). [A Guide to Monitoring and Evaluation for Collaborative TB/HIV Activities: 2015 Revision](http://www.who.int/tb/publications/monitoring-evaluation-collaborative-tb-hiv/en/).",
     "FP2020 (2015). [Measurement Annex](http://progress.familyplanning2020.org/uploads/15/03/FP2020_MeasurementAnnex_2015_Spreads.pdf)."
     ))
names(addres) <- c("Topic", "Resource")

knitr::kable(addres, format = "html") %>%
  html_table_width(c(100,500))
```

## Share Feedback{-}

This book is a work in progress. You'd be doing me a big favor by taking a moment to tell me what you think about this chapter.

```{r CH06feedback, echo=F}
knitr::include_url("https://duke.qualtrics.com/SE/?SID=SV_2gGmY5g1TTEPl3v",
height="600px")
```
